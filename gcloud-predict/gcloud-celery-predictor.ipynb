{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Celery on Kubernetes with Science Abstracts\n",
    "This is the big test.   we will first load the science abstracts and then use them in a test.  \n",
    "## the test\n",
    "Started a cluster on the google cloud.   We have a rabbitMQ server running on JetStream.  \n",
    "The container being used is dbgannon/predictor.   \n",
    "We will grab a subset of the data and push it to the the Queue.   The predictor will return the predicted topic classifications.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_docs(path, name):\n",
    "    filename = path+name+\".p\"\n",
    "    fileobj = open(filename, \"rb\")\n",
    "    z = fileobj.read()\n",
    "    lst = pickle.loads(str(z))\n",
    "    titles = []\n",
    "    sitenames = []\n",
    "    abstracts = []\n",
    "    for i in range(0, len(lst)):\n",
    "        titles.extend([lst[i][0]])\n",
    "        sitenames.extend([lst[i][1]])\n",
    "        abstracts.extend([lst[i][2]])\n",
    "        \n",
    "    print \"done loading \"+filename\n",
    "    return abstracts, sitenames, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading /Users/dennisgannon/Documents/sciml-data/OneDrive-2016-08-09/sciml_data_arxiv.p\n"
     ]
    }
   ],
   "source": [
    "abstracts, sites, titles = load_docs(\"/Users/dennisgannon/Documents/sciml-data/OneDrive-2016-08-09/\", \n",
    "                                     \"sciml_data_arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous-time random walks (CTRWs) on discrete state spaces, ranging from regular lattices to complex networks, are ubiquitous across physics, chemistry, and biology. Models with coarse-grained states, for example those in Markov models of molecular kinetics, or spatial disorder can give rise to memory and non-exponential distributions of waiting times and first-passage statistics. However, existing methods for analyzing CTRWs on complex energy landscapes do not address these effects. We therefore use statistical mechanics of the nonequilibrium path ensemble to characterize first-passage CTRWs on networks with arbitrary connectivity, energy landscape, and waiting time distributions. Our approach is valuable for calculating higher moments (beyond the mean) of path statistics such as path length, time, and action, as well as any conservative or nonconservative force along a path. For homogeneous networks we derive exact relations between these moments, quantifying the validity of approximating a continuous-time process (path times) with its discrete-time projection (path lengths). For more general models we obtain recursion relations, reminiscent of transfer matrix and exact enumeration techniques, to calculate path statistics numerically in an efficient way. We have implemented our recursive algorithm in PathMAN, a Python script that users can easily apply to their model of choice. We demonstrate the algorithm on a few representative examples to show the importance of non-exponential distributions, memory, and coarse-graining in CTRWs.\n",
      "cond-mat.stat-mech\n",
      "Path statistics, memory, and coarse-graining of continuous-time random   walks on networks [cond-mat.stat-mech]\n"
     ]
    }
   ],
   "source": [
    "print abstracts[1300]\n",
    "print sites[1300]\n",
    "print titles[1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_config(subj, basepath):\n",
    "    docpath =basepath+ \"/config/config_\"+subj+\".json\"\n",
    "    with open(docpath, 'rb') as f:\n",
    "        doc = f.read() \n",
    "    z =json.loads(doc)\n",
    "    subject = z['subject']\n",
    "    loadset = z['loadset']\n",
    "    subtopics = []\n",
    "    for w in z['supertopics']:\n",
    "        subtopics.extend([(w[0], w[1])])\n",
    "    return subject, loadset, subtopics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject, loadset, subtopics = read_config(\"all4\", \"/Users/dennisgannon/Documents/sciml-data/OneDrive-2016-08-09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n"
     ]
    }
   ],
   "source": [
    "print subject\n",
    "#print loadset\n",
    "#the loadset is the set of Arxiv subtopics of the subject we are looking for.\n",
    "# the subtopics are the specific subdiciplines in the submect and the corresponding element of the load set in \n",
    "# which they are classified.\n",
    "#subtopics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maintopcs():\n",
    "    maindic = {}\n",
    "    i = 0\n",
    "    for x in subtopics:\n",
    "        maindic[x[0]]= i\n",
    "        i = i+1\n",
    "    return maindic\n",
    "    print subtopics[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maindic = maintopcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Physics': 0, u'bio': 2, u'compsci': 3, u'finance': 4, u'math': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_topic_dict(subtopics):\n",
    "    dic  = {}\n",
    "    for x in subtopics:\n",
    "        maintop = x[0]\n",
    "        subs = x[1]\n",
    "        for s in subs:\n",
    "            dic[s] = maintop\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicdict = make_topic_dict(subtopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7109\n"
     ]
    }
   ],
   "source": [
    "print len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Physics'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicdict[sites[1300]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a train set and test set for facebooks classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftrain = open('/users/dennisgannon/fastText/train.txt','w')\n",
    "ftest =  open('/users/dennisgannon/fastText/test.txt','w')\n",
    "for i in range(int(0.75*len(abstracts))):\n",
    "    j = randint(0,len(abstracts)-1)\n",
    "    if sites[j] != 'nlin.CG' and sites[j]!='none' and abstracts[j].find('$')< 0:\n",
    "        strng = abstracts[j]\n",
    "        k = strng.find('.')\n",
    "        line = strng[0:k]\n",
    "        bigtop =line[0:15]\n",
    "        topic = topicdict[sites[j]]       \n",
    "        label = str(maindic[topic])+' , '+ bigtop + ' , '+line\n",
    "        ftrain.write(label+'.\\n')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now initialize celery and check everything out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app = Celery('predictor', broker='amqp://guest@%s//' % '149.165.157.221', backend='amqp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.task\n",
    "def predict_text(words, i):\n",
    "    return ['local call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.task\n",
    "def print_wait_hello(t, id):\n",
    "    return t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = print_wait_hello.apply_async([5, 4448])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4448]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = predict_text.apply_async([abstracts[1310], 1310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = y.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'rf= compsci, best = compsci, nextb =compsci, cent =bio'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(s, correct):\n",
    "    c1 = s.find(\"rf= \")\n",
    "    l1 = s.find(\",\")\n",
    "    s1 = s[c1+4:l1]\n",
    "    c2 = s.find('best = ')\n",
    "    l2 = s.find(', nextb')\n",
    "    s2 = s[c2+7:l2]\n",
    "    sc = 0\n",
    "    if s1 == correct:\n",
    "        sc = 1\n",
    "    if s2 == correct:\n",
    "        sc = 1\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(x[0], topicdict[sites[1310]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retvals = []\n",
    "correct = []\n",
    "count = 7000\n",
    "offset = 0\n",
    "for i in range(count):\n",
    "    retvals.append(predict_text.apply_async([abstracts[i+offset], i]))\n",
    "    correct.append(sites[i+offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0=1471216681.77\n",
      "t1=1471219020.61\n",
      "time elapsed = 2338.84190822\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = [retval.get() for retval in retvals]\n",
    "t1 = time.time()\n",
    "print \"t0=\"+str(t0)\n",
    "print \"t1=\"+str(t1)\n",
    "print \"time elapsed = \" + str(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one pod\n",
    "\n",
    "for 10  time elapsed = 4.42296910286\n",
    "\n",
    "for 100 time elapsed = 62.9162750244\n",
    "\n",
    "two pods\n",
    "\n",
    "time elapsed = 51.7355389595\n",
    "\n",
    "four pods\n",
    "\n",
    "time elapsed = 35.1132261753\n",
    "\n",
    "8 pods\n",
    "\n",
    "time elapsed = 41.3670258522\n",
    "\n",
    "16 pods\n",
    "\n",
    "time elapsed = 43.4914228916\n",
    "\n",
    "32 pods\n",
    "\n",
    "time elapsed = 56.3568620682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'rf= compsci, best = compsci, nextb =compsci, cent =compsci']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    }
   ],
   "source": [
    "print len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score =0.937982280652\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "nones = 0\n",
    "for i in range(len(correct)):\n",
    "    goof = False\n",
    "    try:\n",
    "        top = topicdict[correct[i]]\n",
    "    except:\n",
    "        nones += 1\n",
    "        goof = True\n",
    "    if goof == False:\n",
    "        tot = tot+score(res[i][0], top)\n",
    "print \"average score =\" + str(tot/(len(correct)-nones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.task\n",
    "def predict(i):\n",
    "    return ['local call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retvals = []\n",
    "correct = []\n",
    "count = 100\n",
    "offset = 6000\n",
    "for i in range(count):\n",
    "    retvals.append(predict.apply_async([offset+ i]))\n",
    "    correct.append(sites[i+6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0=1471369480.84\n",
      "t1=1471369516.73\n",
      "time elapsed = 35.8836040497\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = [retval.get() for retval in retvals]\n",
    "t1 = time.time()\n",
    "print \"t0=\"+str(t0)\n",
    "print \"t1=\"+str(t1)\n",
    "print \"time elapsed = \" + str(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one pod\n",
    "time elapsed = 68.2084679604\n",
    "time elapsed = 67.6506841183\n",
    "time elapsed = 67.5036990643\n",
    "\n",
    "2 pods\n",
    "time elapsed = 35.0938289165\n",
    "time elapsed = 35.3820288181\n",
    "time elapsed = 34.6607341766\n",
    "\n",
    "4 pods\n",
    "time elapsed = 34.8159649372\n",
    "time elapsed = 33.6211850643\n",
    "time elapsed = 34.3667662144\n",
    "\n",
    "5 pods\n",
    "time elapsed = 37.370057106\n",
    "time elapsed = 34.6072402\n",
    "time elapsed = 35.2972719669\n",
    "\n",
    "\n",
    "six pods \n",
    "time elapsed = 36.8534381\n",
    "time elapsed = 34.6813261509\n",
    "time elapsed = 34.833958149\n",
    "\n",
    "ten pods\n",
    "time elapsed = 36.8795990944\n",
    "time elapsed = 35.8836040497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retvals = []\n",
    "count = 100\n",
    "delay = 10\n",
    "for i in range(count):\n",
    "    retvals.append(print_wait_hello.apply_async([delay, i]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0=1471476852.33\n",
      "t1=1471477128.89\n",
      "time elapsed = 276.562952042\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = [retval.get() for retval in retvals]\n",
    "t1 = time.time()\n",
    "print \"t0=\"+str(t0)\n",
    "print \"t1=\"+str(t1)\n",
    "print \"time elapsed = \" + str(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 pod\n",
    "time elapsed = 995.476099014\n",
    "\n",
    "1 surf pod\n",
    "1006.0\n",
    "\n",
    "1 single pod + 1\n",
    "time elapsed = 522.981867075\n",
    "\n",
    "2 pods\n",
    "time elapsed = 494.070230007\n",
    "\n",
    "2 single pods + 1\n",
    "time elapsed = 358.69045186\n",
    "\n",
    "3 single pods + 1\n",
    "time elapsed = 276.562952042\n",
    "\n",
    "4 pods\n",
    "time elapsed = 242.368831873\n",
    "\n",
    "4 single pods +1\n",
    "time elapsed = 235.255094051\n",
    "\n",
    "5 single pods +1\n",
    "time elapsed = 196.179260969\n",
    "\n",
    "6 single pods +1\n",
    "time elapsed = 175.418498993\n",
    "\n",
    "8 pods\n",
    "time elapsed = 120.797874928 time elapsed = 121.223648071\n",
    "\n",
    "16 pods\n",
    "time elapsed = 99.2593250275 time elapsed = 60.8758580685 time elapsed = 61.1965789795\n",
    "\n",
    "32 pods\n",
    "\n",
    "time elapsed = 42.7353610992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalwork = 100*10\n",
    "speedup = totalwork/61.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.39344262295082"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.task\n",
    "def predict_many(i, count):\n",
    "    return ['local call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retvals = []\n",
    "correct = []\n",
    "count = 5\n",
    "offset = 6000\n",
    "for i in range(count):\n",
    "    retvals.append(predict_many.apply_async([offset+ i, 120]))\n",
    "    correct.append(sites[i+6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0=1471380442.69\n",
      "t1=1471380585.48\n",
      "time elapsed = 142.791425943\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = [retval.get() for retval in retvals]\n",
    "t1 = time.time()\n",
    "print \"t0=\"+str(t0)\n",
    "print \"t1=\"+str(t1)\n",
    "print \"time elapsed = \" + str(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 pods 60 tasks of 10 predicts each total work = 600 predicts \n",
    "time elapsed = 184.443963051\n",
    "6 pods 30 tasks of 20 predicts each total work = 600 predicts \n",
    "time elapsed = 176.352622032\n",
    "6 pods 15 tasks of 40 predicts each total work = 600 predicts\n",
    "time elapsed = 146.799216032\n",
    "6 pods 6 tasks of 100 predicts each total work = 600 predicts\n",
    "time elapsed = 180.755970001\n",
    "time elapsed = 179.902398825\n",
    "\n",
    "1 pod 60 tasks of 10 predicts each total work = 600 predicts\n",
    "time elapsed = 394.87173605\n",
    "1 pod 30 tasks of 20 predicts each total work = 600 predicts\n",
    "time elapsed = 387.621109962\n",
    "1 pod 15 tasks of 40 predicts each total work = 600 predicts\n",
    "time elapsed = 382.39035511\n",
    "1 pods 6 tasks of 100 predicts each total work = 600 predicts\n",
    "time elapsed = 373.496650934\n",
    "\n",
    "2 pods 60 tasks of 10 predicts each total work = 600 predicts\n",
    "time elapsed = 194.941056013\n",
    "2 pods 30 tasks of 20 predicts each total work = 600 predicts\n",
    "time elapsed = 188.393370152\n",
    "2 pods 15 tasks of 40 predicts each total work = 600 predicts\n",
    "time elapsed = 198.636164904\n",
    "2 pods 6 tasks of 100 predicts each total work = 600 predicts\n",
    "time elapsed = 181.407305002\n",
    "\n",
    "5 pods 60 tasks of 10 predicts each total work = 600 predicts \n",
    "time elapsed = 144.982601166\n",
    "5 pods 30 tasks of 20 predicts each total work = 600 predicts \n",
    "time elapsed = 145.315975904\n",
    "5 pods 15 tasks of 40 predicts each total work = 600 predicts\n",
    "time elapsed = 144.852874041\n",
    "5 pods 5 tasks of 120 predicts each total work = 600 predicts\n",
    "time elapsed = 142.791425943\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'predict from 6000: finance finance, bio bio, compsci compsci, math math, compsci compsci, Physics bio, Physics Physics, Physics Physics, compsci compsci, compsci Physics, bio bio, math math, Physics Physics, math math, Physics Physics, math compsci, Physics Physics, compsci bio, finance finance, Physics Physics, ']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.task\n",
    "def predict_many_blank(i, count):\n",
    "    return ['local call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retvals = []\n",
    "correct = []\n",
    "count = 300\n",
    "offset = 6000\n",
    "for i in range(count):\n",
    "    retvals.append(predict_many_blank.apply_async([offset+ i, 2]))\n",
    "    correct.append(sites[i+6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0=1471469401.37\n",
      "t1=1471469637.87\n",
      "time elapsed = 236.495509148\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = [retval.get() for retval in retvals]\n",
    "t1 = time.time()\n",
    "print \"t0=\"+str(t0)\n",
    "print \"t1=\"+str(t1)\n",
    "print \"time elapsed = \" + str(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 pods 300 tasks of 2 predicts each total work = 600 predicts \n",
    "time elapsed = 127.197695017\n",
    "5 pods 60 tasks of 10 predicts each total work = 600 predicts \n",
    "time elapsed = 136.39486599 vs. time elapsed = 144.982601166\n",
    "5 pods 30 tasks of 20 predicts each total work = 600 predicts \n",
    "time elapsed = 149.096962929 vs, time elapsed = 145.315975904\n",
    "5 pods 15 tasks of 40 predicts each total work = 600 predicts\n",
    "time elapsed = 144.852874041\n",
    "5 pods 5 tasks of 120 predicts each total work = 600 predicts\n",
    "time elapsed = 142.791425943\n",
    "\n",
    "5 small pods 5 tasks of 120 predicts each total work = 600 predicts\n",
    "time elapsed = 177.240824938 time elapsed = 166.749773979\n",
    "\n",
    "5 small pods 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 116.711094856 time elapsed = 118.18574214\n",
    "1 small pods 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 410.411929846\n",
    "1 small pods 60 tasks of 10 predicts each total work = 600 predicts \n",
    "time elapsed = 377.092034101\n",
    "2 small pods 60 tasks of 10 predicts each total work = 600 predicts\n",
    "time elapsed = 230.348160028 \n",
    "5 small pods 60 tasks of 10 predicts each total work = 600 predicts\n",
    "time elapsed = 152.949729919 time elapsed = 160.996865988\n",
    "\n",
    "6 small pods+1 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 111.748270035 time elapsed = 111.397089005 \n",
    "5 small pods+1 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 112.084007978\n",
    "4 small pods+1 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 107.88885498\n",
    "3 small pods+1 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 144.35948801\n",
    "2 small pods+1 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 144.791702986\n",
    "1 small pods+1 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 236.495509148\n",
    "1 small pods 300 tasks of 2 predicts each total work = 600 predicts\n",
    "time elapsed = 410.411929846\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.806870937790158"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "410/107.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_servers(lis, name):\n",
    "    i = 0\n",
    "    for x in lis:\n",
    "        if x[0].find(name) > 0:\n",
    "            i = i+1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_servers(res, 'mtest-job-jblf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from celery import group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retvals = []\n",
    "calvals = []\n",
    "count = 20\n",
    "offset = 6000\n",
    "for i in range(count):\n",
    "    calvals.append([offset+ i, 20])\n",
    "retvals = group(predict_many_blank.s(i[0],i[1]) for i in calvals).apply_async() \n",
    "#print calvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0=1471457953.51\n",
      "t1=1471458065.06\n",
      "time elapsed = 111.547049046\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "x = retvals.get()\n",
    "t1 = time.time()\n",
    "print \"t0=\"+str(t0)\n",
    "print \"t1=\"+str(t1)\n",
    "print \"time elapsed = \" + str(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 pod 20 tasks of 20 predicts time elapsed = 229.314230919\n",
    "2 pod 20 tasks of 20 predicts time elapsed = 148.924943924\n",
    "4 pod 20 tasks of 20 predicts time elapsed = 114.858204126 time elapsed = 191.920756817\n",
    "5 pod 20 tasks of 20 predicts time elapsed = 154.280801058 time elapsed = 138.789224863 time elapsed = 111.547049046\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'hello from e4ace4fb079b i=6000'],\n",
       " [u'hello from mtest-job-fp3gg i=6001'],\n",
       " [u'hello from mtest-job-bh508 i=6002'],\n",
       " [u'hello from mtest-job-jblf5 i=6003'],\n",
       " [u'hello from mtest-job-sxhzb i=6004'],\n",
       " [u'hello from e4ace4fb079b i=6005'],\n",
       " [u'hello from mtest-job-fp3gg i=6006'],\n",
       " [u'hello from mtest-job-bh508 i=6007'],\n",
       " [u'hello from mtest-job-jblf5 i=6008'],\n",
       " [u'hello from mtest-job-sxhzb i=6009'],\n",
       " [u'hello from e4ace4fb079b i=6010'],\n",
       " [u'hello from mtest-job-fp3gg i=6011'],\n",
       " [u'hello from mtest-job-bh508 i=6012'],\n",
       " [u'hello from mtest-job-jblf5 i=6013'],\n",
       " [u'hello from mtest-job-sxhzb i=6014'],\n",
       " [u'hello from e4ace4fb079b i=6015'],\n",
       " [u'hello from mtest-job-fp3gg i=6016'],\n",
       " [u'hello from mtest-job-bh508 i=6017'],\n",
       " [u'hello from mtest-job-jblf5 i=6018'],\n",
       " [u'hello from mtest-job-sxhzb i=6019']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
